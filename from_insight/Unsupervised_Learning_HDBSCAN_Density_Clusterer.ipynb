{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Sep 24 21:52:30 2018\n",
    "\n",
    "@author: whitneyreiner\n",
    "\"\"\"\n",
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd, matplotlib.pyplot as plt, time\n",
    "import seaborn as sns\n",
    "import hdbscan\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning stuff\n",
    "\n",
    "#change dtype to numeric\n",
    "df['colname'] = pd.to_numeric(df['colname'])\n",
    "\n",
    "#if already in appropriate format, change to datetime\n",
    "df['colname'] = pd.to_datetime(df['colname'])\n",
    "\n",
    "#List-wise deletion of nulls (remove each row where column value is null)\n",
    "df = df~df['colname_where_the_null_is'].isnull()] \n",
    "\n",
    "#check how many null values in two diff columns within a df\n",
    "df[['colname','colname']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may want to first implement sklearn train/test split\n",
    "\n",
    "#define which col data will be in sample\n",
    "trainset = df[['col1', 'col2', 'col_n']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial cluster fitting\n",
    "### https://hdbscan.readthedocs.io/en/latest/\n",
    "## Visit the excellent documentation for HDBSCAN to see how to choose the  *ONE* parameter you MUST set (min_cluster_size).\n",
    "## There are many additional parameters to specify if you think it is appropriate and this includes the distance metric.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial cluster fitting\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5) #see below for ex. of specifying a few addit. params.\n",
    "clusterer.fit(np.radians(sample1Coords)) #fit the clusterer to the data\n",
    "clusterer.labels_ #print the cluster labels \n",
    "\n",
    "######### example of specifying a few additional parameters:\n",
    "##      clusterer = hdbscan.HDBSCAN(metric='haversine', min_cluster_size=5, min_samples=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the array of labels into a df so it is easier to inspect\n",
    "clusterer_labels = pd.DataFrame({'Cluster_no':clusterer.labels_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many clusters are there?\n",
    "clusterer.labels_.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out the clusters, anything assigned to cluster no. -1 is noise\n",
    "clusterer_labels['Cluster_no'].value_counts()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the probabilities for each cluster\n",
    "clusterer_probabilities = clusterer.probabilities_\n",
    "clusterer_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking out the values\n",
    "clusterer_probabilities['Cluster_p'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusterer_probabilities = pd.DataFrame({'Cluster_p':clusterer.probabilities_})\n",
    "\n",
    "#add the labels and probabilities to original dataframe\n",
    "dfclust = pd.concat([df, clusterer_labels, clusterer_probabilities], axis=1)\n",
    "dfclust.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if you have geographic coordinate data and want to use the Haversine function (matric='Haversine') you will need to transform coordinates into radians\n",
    "coordinates_array = df[['latitude', 'longitude']].values\n",
    "radians_array = np.radians(coordinates_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First check out your data points (plotting original un-clustered data)\n",
    "fig, ax = plt.subplots(figsize=[20, 20])\n",
    "plt.scatter(*datacoor.T, s=1, linewidth=0, c='b', alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering and plotting the clusters\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=[#fill in with an int#])\n",
    "clusterer.fit(coordinates_array)\n",
    "\n",
    "#if you are using Haversine function & radians:\n",
    "clusterer = hdbscan.HDBSCAN(metric='haversine', min_cluster_size=[#fill in with an int#])\n",
    "clusterer.fit(np.radians(coordinates_array))\n",
    "#or clusterer.fit(radians_array)\n",
    "\n",
    "#plot clusters with each cluster in a diff. color\n",
    "color_palette = sns.color_palette('deep', 100)\n",
    "cluster_colors = [color_palette[x] if x >= 0\n",
    "                  else (0.5, 0.5, 0.5)\n",
    "                  for x in clusterer.labels_]\n",
    "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                         zip(cluster_colors, clusterer.probabilities_)]\n",
    "fig, ax = plt.subplots(figsize=[20, 20])\n",
    "plt.scatter(*radians_array.T, s=25, linewidth=0, c=cluster_member_colors, alpha=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the clusters\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.5, 's' : 25, 'linewidths':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"hls\", 6500)\n",
    "cluster_colors = [sns.desaturate(palette[col], sat)\n",
    "                  if col >= 0 else (0.5, 0.5, 0.5) for col, sat in\n",
    "                  zip(clusterer.labels_, clusterer.probabilities_)]\n",
    "fig, ax = plt.subplots(figsize=[20, 20])\n",
    "plt.scatter(datacoor.T[0], datacoor.T[1], c=cluster_colors, **plot_kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a condensed tree if you'd like to check out the clusters this way\n",
    "fig, ax = plt.subplots(figsize=[10, 10])\n",
    "clusterer.condensed_tree_.plot(select_clusters=True, selection_palette=sns.color_palette())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fitting new data to clustered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_array= new_data.values\n",
    "#if using radians\n",
    "new_radians = np.radians(new_data)\n",
    "new_radians_array = new_radians.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'training' (already clustered) data = radians_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set it up so it knows it is prediciton data\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5,prediction_data=True)\n",
    "clusterer.fit(coordinates_array)\n",
    "\n",
    "pal = sns.color_palette('deep', 100)\n",
    "colors = [sns.desaturate(pal[col], sat) for col, sat in zip(clusterer.labels_, clusterer.probabilities_)]\n",
    "fig, ax = plt.subplots(figsize=[20, 20])\n",
    "plt.scatter(coordinates_array.T[0], coordinates_array.T[1], c=colors, **plot_kwds);\n",
    "\n",
    "# if you are plotting radians because you are using Haversine function: \n",
    "# MAKE SURE YOU ARE PLOTTING BOTH AS RADS OR BOTH AS COORDINATES!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"test\" points = new_data_array\n",
    "#\"training\" points = coordinates_array\n",
    "fig, ax = plt.subplots(figsize=[20, 20])\n",
    "colors = [sns.desaturate(pal[col], sat) for col, sat in zip(clusterer.labels_, clusterer.probabilities_)]\n",
    "\n",
    "plt.scatter(coordinates_array.T[0], coordinates_array.T[1], c=colors, **plot_kwds); # plot the originally clustered data \"training set\"\n",
    "plt.scatter(*new_data_array.T, c='k', s=80) #overlay the new \"test\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the labels for the \"test\" data\n",
    "test_labels, strengths = hdbscan.approximate_predict(clusterer, test_points)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_df = pd.DataFrame({'test_clust_no': test_labels})\n",
    "test_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can append the cluster labels to the \"test\" set dataframe\n",
    "new_data_df = pd.concat([testsample, test_labelsdf], axis=1)\n",
    "new_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want the \"test\" points to be the same color as the cluster they are assigned to \n",
    "\n",
    "fig, ax = plt.subplots(figsize=[20, 20])\n",
    "\n",
    "colors = [sns.desaturate(pal[col], sat) for col, sat in zip(clusterer.labels_, clusterer.probabilities_)]\n",
    "test_colors = [pal[col] if col >= 0 else (0.1, 0.1, 0.1) for col in test_labels]\n",
    "plt.scatter(coordinates_array.T[0], coordinates_array.T[1], c=colors, **plot_kwds);\n",
    "plt.scatter(*new_data_array.T, c=test_colors, s=100, linewidths=1, edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save as numpy arrays so you can easily load an already clustered set of data and then use the prediction_data=True method on new data laters\n",
    "np.save('train_datacoor',coordinates_array)\n",
    "#save training data radians\n",
    "np.save('train_dataRadians',radians_array)\n",
    "#save clusterer_labels\n",
    "np.save('train_clustLabs',clusterer.labels_)\n",
    "#save clusterer_probabilities\n",
    "np.save('train_clustProbs', clusterer.probabilities_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
