{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "This notebook contains boilerplate code for typical EDA steps:\n",
    "- Import\n",
    "- Summary Stats\n",
    "- Cleaning\n",
    "- Missing data\n",
    "- Exploratory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a csv file without the annoying index column\n",
    "a = pd.read_csv(\"a.csv\", index_col = 0)\n",
    "\n",
    "# Naming columns for a dataframe\n",
    "colnames= ['column1', 'column2', 'etc']\n",
    "a.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining dataframes, SQL style\n",
    "df = a.join(b, how = 'left', on = 'key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing & cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type per column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's often helpful to have a count of unique values in each column:\n",
    "def nunicol(df):\n",
    "    summary = []\n",
    "    for i in range(0, len(df.columns)):\n",
    "        summary.append(df.iloc[:,i].nunique())\n",
    "    \n",
    "    summary = pd.DataFrame([summary])\n",
    "    summary.columns = df.columns\n",
    "    \n",
    "    return summary\n",
    "\n",
    "nunicol(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make crosstab table for initial overview. Also exposes misspelled feature levels.\n",
    "ct = pd.crosstab([df.feature_1, df.feature_2, df.feature_3], df.target, , normalize='index')\n",
    "ct.sort_values(by=1, ascending=False)\n",
    "\n",
    "# normalize by 'index' gives percentages per row\n",
    "# normalize by 'all' gives overall percentages\n",
    "# to access a column, use e.g.: ct.iloc[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing spellings/typos using a dictionary\n",
    "df.replace({'column_name' : { 'wrong_1' : 'correct_1', 'wrong_2': 'correct_2'}}, inplace=True)\n",
    "\n",
    "# display levels after replacing misspellings\n",
    "df.column_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count NaNs in dataframe by column\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows or columns with NaNs\n",
    "df.dropna(axis=0, inplace=True) # axis=0 for rows, axis=1 for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean imputation\n",
    "df.column.fillna(df.column.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation using sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') # or 'median', 'most_frequent', 'constant'\n",
    "# filling the dataframe\n",
    "df_imped = imp.fit_transform(df)\n",
    "\n",
    "# when dealing with separate train/test sets, carry out fit and transfor separately:\n",
    "imp.fit(X_train)\n",
    "X_test = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate distribution plot (Histogram with optional kde and rug plot)\n",
    "sns.distplot(df.column, kde=False, rug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot lines for  distributions\n",
    "def plot_with_fill(x, y, label):\n",
    "    lines = plt.plot(x, y, label=label, lw=2)\n",
    "    plt.fill_between(x, 0, y, alpha=0.2, color=lines[0].get_c())\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "feature_names = list(df.columns[1:10])\n",
    "label_name = list(df.columns[10:])\n",
    "\n",
    "features = df[feature_names]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(features.corr(), annot=True, square=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
